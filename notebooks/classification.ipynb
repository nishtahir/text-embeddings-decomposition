{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import duckdb\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import openai\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>embedding</th>\n",
       "      <th>labels</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[-0.010531049221754074, 0.07523203641176224, -...</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[0.016954615712165833, 0.04743356257677078, -0...</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[-0.02557339146733284, 0.022649677470326424, -...</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[0.004888955038040876, 0.13877353072166443, -0...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[-0.03958750516176224, -0.007721670437604189, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Probably my all-time favorite movie, a story o...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[0.014508235268294811, 0.04683531075716019, -0...</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I sure would like to see a resurrection of a u...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[0.04898536205291748, 0.02820231206715107, -0....</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>This show was an amazing, fresh &amp; innovative i...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[-0.00034545271773822606, 0.058210309594869614...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Encouraged by the positive comments about this...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[-0.02741415984928608, 0.09173857420682907, -0...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>If you like original gut wrenching laughter yo...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[0.017252212390303612, 0.0524253286421299, -0....</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment  \\\n",
       "0  One of the other reviewers has mentioned that ...  positive   \n",
       "1  A wonderful little production. <br /><br />The...  positive   \n",
       "2  I thought this was a wonderful way to spend ti...  positive   \n",
       "3  Basically there's a family where a little boy ...  negative   \n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive   \n",
       "5  Probably my all-time favorite movie, a story o...  positive   \n",
       "6  I sure would like to see a resurrection of a u...  positive   \n",
       "7  This show was an amazing, fresh & innovative i...  negative   \n",
       "8  Encouraged by the positive comments about this...  negative   \n",
       "9  If you like original gut wrenching laughter yo...  positive   \n",
       "\n",
       "                                           embedding  labels  split  \n",
       "0  [-0.010531049221754074, 0.07523203641176224, -...       1  train  \n",
       "1  [0.016954615712165833, 0.04743356257677078, -0...       1  train  \n",
       "2  [-0.02557339146733284, 0.022649677470326424, -...       1  train  \n",
       "3  [0.004888955038040876, 0.13877353072166443, -0...       0  train  \n",
       "4  [-0.03958750516176224, -0.007721670437604189, ...       1  train  \n",
       "5  [0.014508235268294811, 0.04683531075716019, -0...       1  train  \n",
       "6  [0.04898536205291748, 0.02820231206715107, -0....       1  train  \n",
       "7  [-0.00034545271773822606, 0.058210309594869614...       0  train  \n",
       "8  [-0.02741415984928608, 0.09173857420682907, -0...       0  train  \n",
       "9  [0.017252212390303612, 0.0524253286421299, -0....       1  train  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duckdb.sql(\"SELECT * FROM 'dataset/embedded_reviews.parquet' LIMIT 10\").to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39891, 10109)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = duckdb.sql(\n",
    "    \"SELECT embedding, labels FROM 'dataset/embedded_reviews.parquet' WHERE split = 'train'\"\n",
    ").to_df()\n",
    "val_df = duckdb.sql(\n",
    "    \"SELECT embedding, labels FROM 'dataset/embedded_reviews.parquet' WHERE split = 'val'\"\n",
    ").to_df()\n",
    "\n",
    "len(train_df), len(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((tensor([-0.0105,  0.0752, -0.0917,  ...,  0.0197, -0.0065, -0.0305]),\n",
       "  tensor(1)),\n",
       " (tensor([-0.0001,  0.0551, -0.0257,  ...,  0.0023,  0.0300, -0.0256]),\n",
       "  tensor(0)))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class IMDBDataset(Dataset):\n",
    "    def __init__(self, items):\n",
    "        self.items = items\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.items)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.items.iloc[idx]\n",
    "        return torch.tensor(\n",
    "            row[\"embedding\"],\n",
    "            dtype=torch.float32,\n",
    "        ), torch.tensor(\n",
    "            row[\"labels\"],\n",
    "            dtype=torch.long,\n",
    "        )\n",
    "\n",
    "\n",
    "train_dataset = IMDBDataset(train_df)\n",
    "val_dataset = IMDBDataset(val_df)\n",
    "\n",
    "train_dataset[0], val_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(SentimentClassifier, self).__init__()\n",
    "        self.layer_1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.layer_2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.layer_3 = nn.Linear(hidden_dim, output_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.layer_1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.layer_2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.layer_3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "HIDDEN_DIM = 256\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 0.001\n",
    "NUM_EPOCHS = 10\n",
    "\n",
    "input_dim = 1536\n",
    "output_dim = 2\n",
    "num_epochs = 10\n",
    "\n",
    "model = SentimentClassifier(input_dim, HIDDEN_DIM, output_dim)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████| 1247/1247 [00:10<00:00, 117.62it/s, Loss: 0.1267903745174408]  \n",
      "Epoch 1/10: 100%|██████████| 316/316 [00:01<00:00, 215.46it/s, Loss: 0.10470446199178696] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10]\n",
      "Train Loss: 0.1386, Train Acc: 94.84%\n",
      "Val Loss: 0.1510, Val Acc: 94.48%\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|██████████| 1247/1247 [00:10<00:00, 119.20it/s, Loss: 0.22692397236824036] \n",
      "Epoch 2/10: 100%|██████████| 316/316 [00:01<00:00, 243.17it/s, Loss: 0.10231629014015198] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10]\n",
      "Train Loss: 0.1293, Train Acc: 95.29%\n",
      "Val Loss: 0.1432, Val Acc: 94.73%\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|██████████| 1247/1247 [00:10<00:00, 118.86it/s, Loss: 0.19485260546207428] \n",
      "Epoch 3/10: 100%|██████████| 316/316 [00:01<00:00, 245.25it/s, Loss: 0.10211461037397385] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10]\n",
      "Train Loss: 0.1201, Train Acc: 95.61%\n",
      "Val Loss: 0.1406, Val Acc: 94.93%\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|██████████| 1247/1247 [00:10<00:00, 118.17it/s, Loss: 0.04125737398862839] \n",
      "Epoch 4/10: 100%|██████████| 316/316 [00:01<00:00, 234.70it/s, Loss: 0.14750191569328308] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10]\n",
      "Train Loss: 0.1091, Train Acc: 96.02%\n",
      "Val Loss: 0.1516, Val Acc: 94.93%\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|██████████| 1247/1247 [00:10<00:00, 120.54it/s, Loss: 0.025885265320539474] \n",
      "Epoch 5/10: 100%|██████████| 316/316 [00:01<00:00, 237.15it/s, Loss: 0.10867998749017715]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10]\n",
      "Train Loss: 0.0970, Train Acc: 96.47%\n",
      "Val Loss: 0.1507, Val Acc: 95.05%\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|██████████| 1247/1247 [00:10<00:00, 116.27it/s, Loss: 0.13978135585784912] \n",
      "Epoch 6/10: 100%|██████████| 316/316 [00:01<00:00, 242.69it/s, Loss: 0.18212035298347473] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/10]\n",
      "Train Loss: 0.0884, Train Acc: 96.87%\n",
      "Val Loss: 0.1596, Val Acc: 94.59%\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|██████████| 1247/1247 [00:10<00:00, 117.88it/s, Loss: 0.07013380527496338]  \n",
      "Epoch 7/10: 100%|██████████| 316/316 [00:01<00:00, 243.17it/s, Loss: 0.14806626737117767]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/10]\n",
      "Train Loss: 0.0754, Train Acc: 97.28%\n",
      "Val Loss: 0.1585, Val Acc: 95.14%\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|██████████| 1247/1247 [00:10<00:00, 119.50it/s, Loss: 0.32823675870895386]  \n",
      "Epoch 8/10: 100%|██████████| 316/316 [00:01<00:00, 234.99it/s, Loss: 0.09305138140916824] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/10]\n",
      "Train Loss: 0.0673, Train Acc: 97.59%\n",
      "Val Loss: 0.1621, Val Acc: 95.02%\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|██████████| 1247/1247 [00:10<00:00, 119.47it/s, Loss: 0.006871419493108988] \n",
      "Epoch 9/10: 100%|██████████| 316/316 [00:01<00:00, 234.08it/s, Loss: 0.09961969405412674]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/10]\n",
      "Train Loss: 0.0581, Train Acc: 97.85%\n",
      "Val Loss: 0.2018, Val Acc: 94.38%\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|██████████| 1247/1247 [00:10<00:00, 116.12it/s, Loss: 0.0027116890996694565]\n",
      "Epoch 10/10: 100%|██████████| 316/316 [00:01<00:00, 234.44it/s, Loss: 0.22444158792495728]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10]\n",
      "Train Loss: 0.0536, Train Acc: 98.06%\n",
      "Val Loss: 0.2010, Val Acc: 94.70%\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = model.to(device)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "\n",
    "    pbar = tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "    for embeddings, labels in pbar:\n",
    "        embeddings, labels = embeddings.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(embeddings)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        pbar.set_postfix_str(f\"Loss: {loss.item()}\")\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        train_total += labels.size(0)\n",
    "        train_correct += (predicted == labels).sum().item()\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(val_loader, desc=f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "        for embeddings, labels in pbar:\n",
    "            embeddings, labels = embeddings.to(device), labels.to(device)\n",
    "            outputs = model(embeddings)\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            pbar.set_postfix_str(f\"Loss: {loss.item()}\")\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            val_total += labels.size(0)\n",
    "            val_correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}]\")\n",
    "    print(\n",
    "        f\"Train Loss: {train_loss / len(train_loader):.4f}, Train Acc: {100 * train_correct / train_total:.2f}%\"\n",
    "    )\n",
    "    print(\n",
    "        f\"Val Loss: {val_loss / len(val_loader):.4f}, Val Acc: {100 * val_correct / val_total:.2f}%\"\n",
    "    )\n",
    "    print(\"--------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1536"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai = openai.OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "\n",
    "def get_embedding(text):\n",
    "    return openai.embeddings.create(input=text, model=\"text-embedding-3-small\").data[0].embedding\n",
    "\n",
    "\n",
    "len(get_embedding(\"Hello, world!\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# positive = 1\n",
    "# negative = 0\n",
    "\n",
    "ex_1 = torch.tensor(\n",
    "    get_embedding(\"This was a really fun movie. I had a great time.\"),\n",
    "    dtype=torch.float32,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    0.0005,     0.9995]], device='mps:0', grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.set_printoptions(sci_mode=False)\n",
    "\n",
    "logits = model(torch.stack([ex_1]))\n",
    "pred = torch.softmax(logits, dim=1)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1], device='mps:0')"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sentences = [\n",
    "    \"The radiant pulse of hope dances through the quiet corridors of the mind\",\n",
    "    \"A vibrant tapestry of dreams weaves together whispers of joy and resilience.\",\n",
    "    \"In the gentle hum of the cosmos, optimism blooms like a celestial flower.\",\n",
    "    \"The shimmering aura of gratitude paints every moment with soft luminescence.\",\n",
    "    \"A symphony of vibrant energy ignites the spirit, echoing the promise of new beginnings.\",\n",
    "    \"The serene rhythm of a heartbeat reverberates with the melody of endless possibility.\",\n",
    "    \"Embraced by the warm glow of inspiration, the soul finds solace in its own light.\",\n",
    "    \"Each fleeting moment bursts forth with the abstract magic of pure, unfiltered joy.\",\n",
    "    \"The delicate interplay of sunlight and shadow reveals an ever-evolving portrait of positive transformation.\",\n",
    "    \"In the boundless landscape of the heart, every thought radiates with the energy of a thousand smiles.\",\n",
    "]\n",
    "\n",
    "test_embeddings = torch.tensor(\n",
    "    [get_embedding(sentence) for sentence in test_sentences],\n",
    "    dtype=torch.float32,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "model.eval()\n",
    "out = model(test_embeddings)\n",
    "probs = torch.argmax(out, dim=1)\n",
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.03569634, -0.01072521, -0.01411251, ..., -0.02124288,\n",
       "        -0.00842748, -0.01765546],\n",
       "       [ 0.05399539,  0.01783927,  0.00116939, ..., -0.01873825,\n",
       "        -0.01785332, -0.03553807],\n",
       "       [ 0.03057423,  0.01606516,  0.01289535, ..., -0.01048198,\n",
       "         0.04109222,  0.00085369],\n",
       "       ...,\n",
       "       [ 0.0013048 ,  0.0088174 , -0.03082495, ..., -0.02925625,\n",
       "        -0.0014151 ,  0.01362154],\n",
       "       [ 0.02377794, -0.01580558,  0.01782302, ..., -0.01243855,\n",
       "        -0.01554123, -0.00312007],\n",
       "       [ 0.01591483, -0.01888   ,  0.00251744, ..., -0.02223878,\n",
       "         0.00678972,  0.02113668]], shape=(10, 1536), dtype=float32)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def qr_decomposition(mat):\n",
    "    Q, R = np.linalg.qr(mat.T)\n",
    "    return Q, R\n",
    "\n",
    "\n",
    "def projection_matrix(mat):\n",
    "    P = mat @ mat.T\n",
    "    return P\n",
    "\n",
    "\n",
    "test_embeddings.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1536, 1536)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q, R = qr_decomposition(test_embeddings.cpu().numpy())\n",
    "q_proj = projection_matrix(Q)\n",
    "\n",
    "q_proj.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1536,)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex_1 = ex_1.cpu().numpy()\n",
    "\n",
    "ex_1_proj = q_proj @ ex_1\n",
    "ex_1_decomp = ex_1 - ex_1_proj\n",
    "ex_1_decomp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_h/0702xyyn6_56lw_dh373j5240000gp/T/ipykernel_84517/575856699.py:1: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_new.cpp:257.)\n",
      "  pred = model(torch.tensor([ex_1_decomp], dtype=torch.float32, device=device))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[    0.0001,     0.9999]], device='mps:0', grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model(torch.tensor([ex_1_decomp], dtype=torch.float32, device=device))\n",
    "pred.softmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                                           embedding\n",
       " 0  [-0.010531049221754074, 0.07523203641176224, -...\n",
       " 1  [0.016954615712165833, 0.04743356257677078, -0...\n",
       " 2  [-0.02557339146733284, 0.022649677470326424, -...\n",
       " 3  [-0.03958750516176224, -0.007721670437604189, ...\n",
       " 4  [0.014508235268294811, 0.04683531075716019, -0...,\n",
       " 25000)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_val = duckdb.sql(\n",
    "    \"SELECT embedding FROM 'dataset/embedded_reviews.parquet' WHERE labels = 1\"\n",
    ").to_df()\n",
    "positive_val.head(), len(positive_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    0.0004,     0.9996],\n",
       "        [    0.1166,     0.8834]], device='mps:0', grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the qr decomposition of the positive reviews\n",
    "positive_embeddings = torch.tensor(\n",
    "    positive_val[\"embedding\"].tolist(), dtype=torch.float32, device=device\n",
    ")\n",
    "Q, R = qr_decomposition(positive_embeddings.cpu().numpy())\n",
    "q_proj = projection_matrix(Q)\n",
    "\n",
    "ex_1 = torch.tensor(\n",
    "    get_embedding(\"This was a fun movie, i had a great time\"),\n",
    "    dtype=torch.float32,\n",
    "    device=device,\n",
    ")\n",
    "ex_1 = ex_1.cpu().numpy()\n",
    "\n",
    "ex_1_proj = q_proj @ ex_1\n",
    "ex_1_decomp = ex_1 - ex_1_proj\n",
    "\n",
    "pred = model(torch.tensor([ex_1, ex_1_decomp], dtype=torch.float32, device=device))\n",
    "pred.softmax(dim=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
